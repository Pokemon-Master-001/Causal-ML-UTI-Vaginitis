{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed6e688-bb3f-490e-8c36-445cc889a50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dill\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.metrics import (matthews_corrcoef,auc,roc_auc_score, average_precision_score, accuracy_score,\n",
    "                             precision_score, recall_score, f1_score, brier_score_loss,\n",
    "                             roc_curve, precision_recall_curve)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import shap\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a9b98f-fa4b-488b-ae62-71d636668dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary \n",
    "D_ICD_DIAGNOSES = pd.read_csv('/mimic-iii-clinical-database-1.4/D_ICD_DIAGNOSES.csv.gz')\n",
    "D_ICD_DIAGNOSES.columns = D_ICD_DIAGNOSES.columns.str.upper()\n",
    "D_ICD_DIAGNOSES['ICD_VERSION'] = 9\n",
    "D_ICD_DIAGNOSES = D_ICD_DIAGNOSES[['ICD9_CODE','ICD_VERSION','LONG_TITLE']]\n",
    "D_ICD_DIAGNOSES.columns = ['ICD_CODE', 'ICD_VERSION', 'ICD_TEXT']\n",
    "print(D_ICD_DIAGNOSES.shape)\n",
    "\n",
    "D_4_DIAGNOSES = pd.read_csv('C:/MIMIC IV/3.1/hosp/D_ICD_DIAGNOSES.csv.gz')\n",
    "D_4_DIAGNOSES.columns = D_4_DIAGNOSES.columns.str.upper()\n",
    "D_4_DIAGNOSES.columns = ['ICD_CODE', 'ICD_VERSION', 'ICD_TEXT']\n",
    "print(D_4_DIAGNOSES.shape)\n",
    "\n",
    "D_ICD_DIAGNOSES = pd.concat([D_ICD_DIAGNOSES,D_4_DIAGNOSES])\n",
    "D_ICD_DIAGNOSES = D_ICD_DIAGNOSES.drop_duplicates(keep='first')\n",
    "print(D_ICD_DIAGNOSES.shape)\n",
    "\n",
    "d_iii_icd_procedures = pd.read_csv('/mimic-iii-clinical-database-1.4/d_icd_procedures.csv.gz')\n",
    "d_iii_icd_procedures = d_iii_icd_procedures.rename(columns={'ICD9_CODE':'ICD_CODE'})\n",
    "d_iii_icd_procedures = d_iii_icd_procedures.rename(columns={'LONG_TITLE':'ICD_TEXT'})\n",
    "d_iii_icd_procedures['ICD_VERSION'] = 9\n",
    "d_iii_icd_procedures = d_iii_icd_procedures[['ICD_CODE', 'ICD_VERSION', 'ICD_TEXT']]\n",
    "d_iii_icd_procedures['ICD_CODE'] = d_iii_icd_procedures['ICD_CODE'].astype(str)\n",
    "\n",
    "d_iv_icd_procedures = pd.read_csv('C:/MIMIC IV/3.1/hosp/d_icd_procedures.csv.gz')\n",
    "d_iv_icd_procedures.columns = ['ICD_CODE', 'ICD_VERSION', 'ICD_TEXT']\n",
    "d_iv_icd_procedures['ICD_CODE'] = d_iv_icd_procedures['ICD_CODE'].astype(str)\n",
    "\n",
    "P_ICD_procedures = pd.concat([d_iii_icd_procedures,d_iv_icd_procedures])\n",
    "P_ICD_procedures = P_ICD_procedures.drop_duplicates(keep='first')\n",
    "\n",
    "dd = P_ICD_procedures[P_ICD_procedures.duplicated(subset=['ICD_TEXT'],keep=False)].sort_values(by='ICD_TEXT')\n",
    "dd = (\n",
    "    dd.groupby('ICD_TEXT')\n",
    "    .agg(\n",
    "        final_ICD_CODE=('ICD_CODE', lambda x: max(x, key=len)), \n",
    "        all_ICD_CODEs=('ICD_CODE', lambda x: list(x))            \n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "P_ICD_procedures = (\n",
    "    P_ICD_procedures.assign(code_len=P_ICD_procedures['ICD_CODE'].str.len())\n",
    "    .sort_values('code_len', ascending=False)\n",
    "    .drop_duplicates(subset=['ICD_TEXT'], keep='first')\n",
    "    .drop(columns='code_len')\n",
    ")\n",
    "\n",
    "print(P_ICD_procedures.ICD_VERSION.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645e26c0-f19e-420c-8663-10ca96e97ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sclar_coder(rundf,num_v,cate_v):\n",
    "    scaler = MinMaxScaler()\n",
    "    rundf[num_v] = scaler.fit_transform(rundf[num_v])\n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "    for col in cate_v:\n",
    "        rundf[col] = label_encoder.fit_transform(rundf[col])\n",
    "\n",
    "    return rundf\n",
    "\n",
    "def print_top_features(all_importances, D_ICD_DIAGNOSES, P_ICD_procedures, sort_by='xgboost', top_n=20):\n",
    "\n",
    "    # Print header\n",
    "    print(f\"---------- Top {top_n} Feature Importances (Sorted by {sort_by}) ----------\")\n",
    "\n",
    "    # Sort features by specified model and get top N\n",
    "    top_features = all_importances.sort_values(by=sort_by, ascending=False).Feature.head(top_n).values\n",
    "\n",
    "    for feature in top_features:\n",
    "        if '_' in feature:\n",
    "            try:\n",
    "                # Split feature name and use the second part as ICD_CODE\n",
    "                icd_code = feature.split('_')[-1]\n",
    "                \n",
    "                # Check D_ICD_DIAGNOSES\n",
    "                diag_match = D_ICD_DIAGNOSES[D_ICD_DIAGNOSES['ICD_CODE'] == icd_code]\n",
    "                if not diag_match.empty:\n",
    "                    print(f\"{feature}: {diag_match['ICD_TEXT'].values[0]}\")\n",
    "                \n",
    "                # Check P_ICD_procedures\n",
    "                proc_match = P_ICD_procedures[P_ICD_procedures['ICD_CODE'] == icd_code]\n",
    "                if not proc_match.empty:\n",
    "                    print(f\"{feature}: {proc_match['ICD_TEXT'].values[0]}\")\n",
    "                \n",
    "                # If no match found in either DataFrame\n",
    "                if diag_match.empty and proc_match.empty:\n",
    "                    print(f\"{feature}: No matching ICD code found\")\n",
    "                    \n",
    "            except IndexError:\n",
    "                print(f\"{feature}: No valid ICD code (malformed feature name)\")\n",
    "        else:\n",
    "            print(feature)\n",
    "    return top_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42351eb3-fa71-4982-96be-224b4fd450b2",
   "metadata": {},
   "source": [
    "## ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d03b2fde-7db4-43b7-8429-7c01f45c7578",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel:\n",
    "    @staticmethod\n",
    "    def get_classifier(model_type='random_forest',label_column=None, params=None):\n",
    "        \"\"\"Return a classifier based on model_type with given parameters.\"\"\"\n",
    "        if params is None:\n",
    "            params = {}\n",
    "        if model_type == 'Random Forest':\n",
    "            return RandomForestClassifier(**params)\n",
    "        elif model_type == 'Decision Tree':\n",
    "            return DecisionTreeClassifier(**params)\n",
    "        elif model_type == 'Adaboost':\n",
    "            return AdaBoostClassifier(**params)\n",
    "        elif model_type == 'XGboost':\n",
    "            return XGBClassifier(**params)\n",
    "        elif model_type == 'LR':\n",
    "            return LogisticRegression(**params)\n",
    "        elif model_type == 'SVM':\n",
    "            return SVC(**params)\n",
    "        elif model_type == 'MLP':\n",
    "            return MLPClassifier(**params)\n",
    "        elif model_type == 'ensemble':\n",
    "            base_models = [\n",
    "                ('rf', RandomForestClassifier()),\n",
    "                ('xgb', XGBClassifier(eval_metric='mlogloss'))\n",
    "            ]\n",
    "            base_models = [(f'model_{i}', model) for i, model in enumerate(base_models)]\n",
    "            return VotingClassifier(estimators=base_models, voting='soft', n_jobs=1)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown model_type: {model_type}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def bootstrap(train, valid, test, label_column, models, n=10, confidence=0.95):\n",
    "        \"\"\"Perform bootstrap cross-validation, evaluate models\"\"\"\n",
    "        # Validate inputs\n",
    "        if label_column not in train.columns or label_column not in test.columns:\n",
    "            raise ValueError(f\"Label column '{label_column}' not found in train or test DataFrame.\")\n",
    "\n",
    "\n",
    "        skf = StratifiedKFold(n_splits=n, shuffle=True, random_state=42)\n",
    "        features = train.columns.difference([label_column])\n",
    "\n",
    "        all_scores = []\n",
    "        all_importances = []\n",
    "        all_AUROC = []\n",
    "        all_AUPRC = []\n",
    "\n",
    "        for model_type, params in models:\n",
    "            scores_model = []\n",
    "            importances_model = pd.DataFrame({'Feature': features})\n",
    "            this_AUROC = []\n",
    "            this_AUPRC = []\n",
    "\n",
    "            for fold, (train_index, val_index) in enumerate(tqdm(skf.split(train, train[label_column]), total=n, desc=f'Model: {model_type}', ascii=True)):\n",
    "                # Use train and validation splits from StratifiedKFold\n",
    "                X_train = train.iloc[train_index][features]\n",
    "                y_train = train.iloc[train_index][label_column]\n",
    "                X_val = valid[features]\n",
    "                y_val = valid[label_column]\n",
    "                X_test = pd.concat([test[features], train.iloc[val_index][features]])\n",
    "                y_test = pd.concat([test[label_column], train.iloc[val_index][label_column]])\n",
    "\n",
    "                # Initialize and train the model\n",
    "                est = BaseModel.get_classifier(model_type, label_column, params)\n",
    "                if model_type == 'autogluon':\n",
    "                    train_data = train.iloc[train_index][list(features) + [label_column]].copy()\n",
    "                    est.fit(train_data, hyperparameter_tune_kwargs='auto')\n",
    "                else:\n",
    "                    if model_type == 'tabnet':\n",
    "                        est.fit(\n",
    "                            X_train.to_numpy(), y_train,\n",
    "                            eval_set=[(X_val.to_numpy(), y_val)],\n",
    "                            eval_metric=['auc']\n",
    "                        )\n",
    "                    else:\n",
    "                        est.fit(X_train, y_train)\n",
    "\n",
    "                # Get predictions and probabilities\n",
    "                if model_type == 'autogluon':\n",
    "                    y_pred = est.predict(test[list(features) + [label_column]])\n",
    "                    y_prob = est.predict_proba(test[list(features) + [label_column]]).iloc[:, 1].values\n",
    "                elif model_type == 'tabnet':\n",
    "                    y_pred = est.predict(X_test.to_numpy())\n",
    "                    y_prob = np.zeros_like(y_pred)\n",
    "                else:\n",
    "                    y_pred = est.predict(X_test)\n",
    "                    try:\n",
    "                        y_prob = est.predict_proba(X_test)[:, 1]\n",
    "                    except AttributeError:\n",
    "                        y_prob = np.zeros_like(y_pred)\n",
    "\n",
    "                # Evaluate AUROC\n",
    "                fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "                roc_auc = auc(fpr, tpr)\n",
    "                this_AUROC.append({'roc_auc': roc_auc, 'fpr': fpr, 'tpr': tpr})\n",
    "\n",
    "                # Evaluate AUPRC\n",
    "                precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
    "                prc_auc = auc(recall, precision)\n",
    "                this_AUPRC.append({'prc_auc': prc_auc, 'precision': precision, 'recall': recall})\n",
    "\n",
    "                # Compute other metrics\n",
    "                accuracy = accuracy_score(y_test, y_pred)\n",
    "                precision_score_val = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "                recall_score_val = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "                f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "                mcc = matthews_corrcoef(y_test, y_pred)\n",
    "                brier = brier_score_loss(y_test, y_prob) if y_prob is not None else np.nan\n",
    "\n",
    "                # Store evaluation metrics\n",
    "                scores_model.append({\n",
    "                    'ROC_AUC': roc_auc,\n",
    "                    'PRC_AUC': prc_auc,\n",
    "                    'Accuracy': accuracy,\n",
    "                    'Precision': precision_score_val,\n",
    "                    'Recall': recall_score_val,\n",
    "                    'F1': f1,\n",
    "                    'MCC': mcc,\n",
    "                    'Brier': brier\n",
    "                })\n",
    "\n",
    "                # Calculate feature importance\n",
    "                if model_type == 'autogluon':\n",
    "                    importance = est.feature_importance(X_test).importance.values\n",
    "                elif hasattr(est, 'feature_importances_'):\n",
    "                    importance = est.feature_importances_\n",
    "                elif hasattr(est, 'coef_') and est.coef_.ndim == 1:\n",
    "                    importance = np.abs(est.coef_)\n",
    "                else:\n",
    "                    importance = np.zeros(len(features))\n",
    "\n",
    "                importances_model[f'fold_{fold}'] = importance\n",
    "\n",
    "            # Aggregate scores\n",
    "            scores_model = pd.DataFrame(scores_model)\n",
    "            all_scores.append(scores_model)\n",
    "\n",
    "            # Aggregate feature importance\n",
    "            importances_model[f'{model_type}_mean'] = importances_model.filter(like='fold_').mean(axis=1)\n",
    "            all_importances.append(importances_model[['Feature', f'{model_type}_mean']])\n",
    "\n",
    "            # Calculate confidence intervals for AUROC and AUPRC\n",
    "            lower_bound = (1 - confidence) / 2\n",
    "            upper_bound = 1 - lower_bound\n",
    "\n",
    "            auroc_vals = [x['roc_auc'] for x in this_AUROC]\n",
    "            auprc_vals = [x['prc_auc'] for x in this_AUPRC]\n",
    "            auroc_ci = (np.percentile(auroc_vals, lower_bound * 100), np.percentile(auroc_vals, upper_bound * 100))\n",
    "            auprc_ci = (np.percentile(auprc_vals, lower_bound * 100), np.percentile(auprc_vals, upper_bound * 100))\n",
    "\n",
    "            all_AUROC.append({\n",
    "                'model': model_type,\n",
    "                'mean': np.mean(auroc_vals),\n",
    "                'ci_lower': auroc_ci[0],\n",
    "                'ci_upper': auroc_ci[1],\n",
    "                'curves': this_AUROC\n",
    "            })\n",
    "            all_AUPRC.append({\n",
    "                'model': model_type,\n",
    "                'mean': np.mean(auprc_vals),\n",
    "                'ci_lower': auprc_ci[0],\n",
    "                'ci_upper': auprc_ci[1],\n",
    "                'curves': this_AUPRC\n",
    "            })\n",
    "\n",
    "\n",
    "        # Combine all scores\n",
    "        all_scores_df = pd.concat([df.assign(Model=model_type) for (model_type, _), df in zip(models, all_scores)], ignore_index=True)\n",
    "        all_scores_summary = all_scores_df.groupby('Model').agg(\n",
    "            {col: lambda x: f\"{np.mean(x):.4f} ({np.percentile(x, lower_bound * 100):.4f}-{np.percentile(x, upper_bound * 100):.4f})\"\n",
    "             for col in all_scores_df.columns if col != 'Model'}\n",
    "        ).reset_index()\n",
    "\n",
    "        # Combine all importances\n",
    "        all_importances_df = pd.concat([df.rename(columns={f'{model_type}_mean': model_type}) for (model_type, _), df in zip(models, all_importances)], axis=1)\n",
    "        all_importances_df = all_importances_df.loc[:, ~all_importances_df.columns.duplicated()]\n",
    "\n",
    "        return all_AUROC, all_AUPRC, all_scores_summary, all_importances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e29f2a-5497-4a27-b026-c481dcc6b856",
   "metadata": {},
   "outputs": [],
   "source": [
    "III_IV = pd.read_csv('/IV_III.csv')\n",
    "III_IV = III_IV[III_IV['Group_Va_uti']==1]\n",
    "print(III_IV.shape)\n",
    "\n",
    "basic = ['GENDER', 'ADMISSION_TYPE', 'FIRST_CAREUNIT', 'AGE']\n",
    "groups = ['Group_AKI', 'Group_CKD', 'Group_PCOS', 'Group_Neoplasm_ovary', 'Group_Endometriosis', 'Group_Leiomyoma']\n",
    "\n",
    "label = ['LOS_Hospital','DIEINHOSPITAL','Readmission_30','Multiple_ICUs','sepsis_all', 'FirstICU24_AKI_ALL','ICU_within_12hr_of_admit']\n",
    "\n",
    "print('Diag:',len(Diag), 'full_Diag:', len(full_Diag),'Proc:',len(Proc),'full_Proc:',len(full_Proc),'Med:',len(Med),'TS:',len(TS),'label:',len(label))\n",
    "\n",
    "\n",
    "num_v = Med + TS + ['AGE']\n",
    "\n",
    "cate_v = ['GENDER','ADMISSION_TYPE','FIRST_CAREUNIT'] + Diag + Proc + label\n",
    "\n",
    "\n",
    "III_IV[Diag + Proc + Med] = III_IV[Diag + Proc + Med].fillna(0)\n",
    "\n",
    "III_IV[TS] = III_IV[TS].fillna(III_IV[TS].median())\n",
    "\n",
    "def sclar_coder(rundf,num_v,cate_v):\n",
    "    scaler = MinMaxScaler()\n",
    "    rundf[num_v] = scaler.fit_transform(rundf[num_v])\n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "    for col in cate_v:\n",
    "        rundf[col] = label_encoder.fit_transform(rundf[col])\n",
    "\n",
    "    return rundf\n",
    "\n",
    "rundf = sclar_coder(III_IV,num_v,cate_v)\n",
    "rundf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919b41c7-1f63-41ad-a73c-8f985ef04636",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runbase(df,thislabel,ft,topf):\n",
    "    ft = ft + [thislabel]\n",
    "    print(thislabel,Counter(df[thislabel]),'len(ft):',len(ft))\n",
    "\n",
    "    Train, Test = train_test_split(df, test_size=0.3, random_state=42)\n",
    "    Valid, Test = train_test_split(Test, test_size=0.25, random_state=42)\n",
    "    print(Train.shape,Valid.shape,Test.shape)\n",
    "    print('Train:',Counter(Train[thislabel]))\n",
    "    print('Test:',Counter(Test[thislabel]))\n",
    "\n",
    "    all_AUROC, all_AUPRC, all_scores, all_importances = BaseModel.bootstrap(\n",
    "       Train[ft], Valid[ft], Test[ft], thislabel, models, n=1000, confidence=0.95\n",
    "    )\n",
    "\n",
    "    all_importances['XGB_RF'] = all_importances['XGboost'] + all_importances['Random Forest'] \n",
    "    top_xgboost = print_top_features(all_importances, D_ICD_DIAGNOSES, P_ICD_procedures, sort_by='XGboost', top_n=topf)\n",
    "    top_rf = print_top_features(all_importances, D_ICD_DIAGNOSES, P_ICD_procedures, sort_by='Random Forest', top_n=topf)\n",
    "    top_XGB_RF = print_top_features(all_importances, D_ICD_DIAGNOSES, P_ICD_procedures, sort_by='XGB_RF', top_n=topf)\n",
    "    \n",
    "    print('label',thislabel)\n",
    "    print('top_xgboost',list(top_xgboost))\n",
    "    print('top_rf',list(top_rf))\n",
    "    print('top_XGB_RF',list(top_XGB_RF))\n",
    "    \n",
    "    return all_AUROC, all_AUPRC, all_scores, all_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae118a66-edc3-4279-b130-0507bde1d7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = basic + Diag + Proc + Med + TS\n",
    "print(len(ft))\n",
    "\n",
    "models = [\n",
    "    ('SVM', {'probability': True}),\n",
    "    ('LR', {}),\n",
    "    ('Decision Tree',{}),\n",
    "    ('Random Forest', {}),\n",
    "    ('Adaboost',{}),\n",
    "    ('XGboost', {}),\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa18f60-93bf-4dca-a0fd-6381cac946ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc746be-d44d-4ee8-83aa-43c9d1fb3d62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t_label = 'DIEINHOSPITAL'\n",
    "t_f = 'ft'\n",
    "all_AUROC, all_AUPRC, all_scores, all_importances = runbase(rundf[rundf.MIMIC == mic],t_label,ft,5)\n",
    "all_scores.style.highlight_max(color='lightgreen', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d73900c-0504-4b84-92c1-fe4cdd4e068e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09b90d4-463c-4777-aa99-48c919938c05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t_label = 'Readmission_30'\n",
    "t_f = 'ft'\n",
    "all_AUROC, all_AUPRC, all_scores, all_importances = runbase(rundf[rundf.MIMIC == mic],'Readmission_30',ft,20)\n",
    "all_scores.style.highlight_max(color='lightgreen', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edd582c-c8d4-4bbd-a5f1-64a3be9c7c8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e82d50d-a131-4c1a-913b-661070063efc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t_label = 'Multiple_ICUs'\n",
    "t_f = 'ft'\n",
    "all_AUROC, all_AUPRC, all_scores, all_importances = runbase(rundf[rundf.MIMIC == mic],'Multiple_ICUs',ft,5)\n",
    "all_scores.style.highlight_max(color='lightgreen', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1509b3-e541-405c-932d-66468cad580f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0611a22a-c174-4dc7-b84d-82bd2c1b5594",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t_label = 'sepsis_all'\n",
    "t_f = 'ft'\n",
    "all_AUROC, all_AUPRC, all_scores, all_importances = runbase(rundf[rundf.MIMIC == mic],'sepsis_all',ft,5)\n",
    "all_scores.style.highlight_max(color='lightgreen', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f64c71-9164-4afa-b14a-f016660cc8ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40306118-aa6e-4011-ac15-d77f0a41c71b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t_label = 'FirstICU24_AKI_ALL'\n",
    "t_f = 'ft'\n",
    "all_AUROC, all_AUPRC, all_scores, all_importances = runbase(rundf[rundf.MIMIC == mic],'FirstICU24_AKI_ALL',ft,5)\n",
    "all_scores.style.highlight_max(color='lightgreen', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0191e960-2288-41b8-97e6-cb802300ff0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372c5cfd-3e89-4451-9a54-b427e984f176",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t_label = 'LOS_Hospital'\n",
    "t_f = 'ft'\n",
    "all_AUROC, all_AUPRC, all_scores, all_importances = runbase(rundf[rundf.MIMIC == mic],'LOS_Hospital',ft,5)\n",
    "all_scores.style.highlight_max(color='lightgreen', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914c2734-62ff-4977-96ee-f3c94dd7bfd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debd526f-2d1a-4ba3-b816-fc1c6b62da16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t_label = 'ICU_within_12hr_of_admit'\n",
    "t_f = 'ft'\n",
    "ft_icu12 = basic + Diag\n",
    "print(len(ft_icu12))\n",
    "all_AUROC, all_AUPRC, all_scores, all_importances = runbase(rundf[rundf.MIMIC == mic],'ICU_within_12hr_of_admit',ft_icu12,15)\n",
    "all_scores.style.highlight_max(color='lightgreen', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f096a5-db3e-458b-abad-99b132566d4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
